{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sci.med', 'comp.graphics']\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                                remove=('headers', 'footers', 'quotes'), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': newsgroups.data,\n",
    "    'target': newsgroups.target,\n",
    "    'category': [categories[i] for i in newsgroups.target]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1963, 3)\n",
      "Category distribution:\n",
      "category\n",
      "comp.graphics    990\n",
      "sci.med          973\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Category distribution:\\n{df['category'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample texts from each category:\n",
      "\n",
      "sci.med: Hi all,\n",
      "\n",
      "  I am looking for a recommandation on a good royalty free graphics\n",
      "library package for C and C++ program.  This is mainly use to write\n",
      "children games and education software.  I heard someone...\n",
      "\n",
      "comp.graphics: \n",
      "You certainly do not see OTC preparations advertised as such.\n",
      "The only such ridiculous concoctions are nostrums for premenstrual\n",
      "syndrome, ostensibly to treat headache and \"bloating\" simultaneously.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample texts from each category:\")\n",
    "for category in categories:\n",
    "    sample_text = df[df['category'] == category]['text'].iloc[0][:200] + \"...\"\n",
    "    print(f\"\\n{category}: {sample_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Frequent Words (Custom Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_words(texts, n=50):\n",
    "    all_words = ' '.join(texts).split()\n",
    "    word_freq = Counter(all_words)\n",
    "    return [word for word, freq in word_freq.most_common(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom stopwords (top 10): ['that', 'of', 'is', 'by', 'in', 'to', 'with', 'and', 'can', 'it']\n"
     ]
    }
   ],
   "source": [
    "frequent_words = get_frequent_words(df['cleaned_text'].tolist(), 30)\n",
    "custom_stopwords = set(frequent_words)\n",
    "\n",
    "print(f\"Custom stopwords (top 10): {list(custom_stopwords)[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stop_words):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['cleaned_text'].apply(\n",
    "    lambda x: remove_stopwords(x, custom_stopwords)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Cleaned and Original Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Cleaned Text Comparison:\n",
      "\n",
      "Original text:\n",
      "\n",
      "And to add further fuel to the flame war, I read about 20 years ago that\n",
      "the \"natural\" MSG - extracted from the sources you mention above - does not\n",
      "...\n",
      "\n",
      "Cleaned text:\n",
      "add further fuel flame war read about years ago natural msg extracted sources mention above does cause reported aftereffects its only nasty artificial...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal vs Cleaned Text Comparison:\")\n",
    "sample_idx = 10\n",
    "print(f\"\\nOriginal text:\\n{df['text'].iloc[sample_idx][:150]}...\")\n",
    "print(f\"\\nCleaned text:\\n{df['processed_text'].iloc[sample_idx][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1374\n",
      "Test set size: 589\n"
     ]
    }
   ],
   "source": [
    "X = df['processed_text']\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
